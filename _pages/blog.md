---
permalink: /blog
title: ''
excerpt: ''
author_profile: true
redirect_from:
---

# ðŸ‘“ Reading

- Fundamental Theory

  - Fundamental Modal

    - <details>
        <summary>Transformer</summary>
        <b>Aim:</b>
        <div></div>
        <b>Pros:</b>
        <div></div>
        <b>Cons:</b>
        <div></div>
      </details>

    - <details>
        <summary>Bert</summary>
        <b>Aim:</b>
        <div></div>
        <b>Pros:</b>
        <div></div>
        <b>Cons:</b>
        <div></div>
      </details>

  - Multimodal Modal

- Alignment

- VLM
  - Macroscopic Perspective
  - <details>
      <summary>Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs</summary>
      <b>Aim:</b>
      <div>Let AI learn to design multimodal models with a visual focus that enhances visual capabilities to drive AI understanding and decision-making. The focus shifts from scaling LLMs to enhancing visual representations.</div>
      <b>Contribution:</b>
      <div>CV-Bench: presents a new vision-centered benchmark for more accurate evaluation of visual perception in multimodal large language models.</div>
      <div>
      Spatial Vision Aggregator (SVA): A dynamic and spatially aware connector is proposed that integrates high-resolution visual features while reducing the number of tokens required for processing. Improved information integration efficiency and accuracy are achieved.</div>
      <b>Future research directions:</b>
      <div>pure visual models and their integration into MLLM. And these models should utilize large-scale datasets more effectively and maintain the advantages of a strong visual foundation.</div>
    </details>
